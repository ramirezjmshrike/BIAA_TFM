{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc33f4be",
   "metadata": {},
   "source": [
    "# Carga de librerías y métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f52b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from mmseg.apis import init_model, inference_model, show_result_pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/home/joan_ds/Sandbox/UOC/TFM/trials_imgs'\n",
    "tmp_dir = 'DeepLabV3Plus-Pytorch/tmp_resized'\n",
    "output_dir = 'DeepLabV3Plus-Pytorch/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = \"/home/joan_ds/mmseg_assets/ocrnet_hr48_4xb2-160k_cityscapes-512x1024.py\"\n",
    "ckpt = \"/home/joan_ds/mmseg_assets/ocrnet_hr48_512x1024_160k_cityscapes_20200602_191037-dfbf1b0c.pth\"\n",
    "\n",
    "\n",
    "model = init_model(cfg, ckpt, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c285dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITYSCAPES_ID2COLOR = {\n",
    "    0: (128, 64, 128),  # road (RGB)\n",
    "    1: (244, 35, 232),  # sidewalk (RGB)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c987143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mask_ids(ids_map):\n",
    "    \n",
    "    h, w = ids_map.shape\n",
    "    mask_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    present_classes = []\n",
    "    for class_id, color in CITYSCAPES_ID2COLOR.items():\n",
    "        m = (ids_map == class_id)\n",
    "        if m.any():\n",
    "            mask_rgb[m] = color\n",
    "            present_classes.append(class_id)\n",
    "    return mask_rgb, present_classes\n",
    "\n",
    "def extract_ids_and_conf(result):\n",
    "    \n",
    "    ids_map = result.pred_sem_seg.data[0].cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    conf_map = None\n",
    "    if hasattr(result, 'seg_logits') and result.seg_logits is not None:\n",
    "        logits = result.seg_logits\n",
    "        if hasattr(logits, \"data\"):   # PixelData -> tensor\n",
    "            logits = logits.data\n",
    "        if isinstance(logits, torch.Tensor):\n",
    "            if logits.dim() == 4:     # [1, C, H, W]\n",
    "                logits = logits[0]\n",
    "            if logits.dim() == 3 and logits.shape[0] > 1:  # [C,H,W]\n",
    "                probs = torch.softmax(logits, dim=0)\n",
    "                conf_map = probs.max(0).values.cpu().numpy().astype(np.float32)\n",
    "            elif logits.dim() == 3 and logits.shape[0] == 1:  # [1,H,W]\n",
    "                conf_map = torch.sigmoid(logits[0]).cpu().numpy().astype(np.float32)\n",
    "            elif logits.dim() == 2:  # [H,W]\n",
    "                conf_map = torch.sigmoid(logits).cpu().numpy().astype(np.float32)\n",
    "    return ids_map, conf_map\n",
    "\n",
    "def mask_pred_hrnet(model, input_dir,\n",
    "                    output_dir=\"hrnet_output\", save_ids_conf=True, save_vis=True, alpha=0.5):\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    results_lst = []\n",
    "\n",
    "    files = [f for f in sorted(os.listdir(input_dir)) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    for fname in files:\n",
    "        stem = os.path.splitext(fname)[0]\n",
    "        img_path = os.path.join(input_dir, fname)\n",
    "\n",
    "        result = inference_model(model, img_path)\n",
    "        ids_map, conf_map = extract_ids_and_conf(result)\n",
    "\n",
    "        original_bgr = cv2.imread(img_path)\n",
    "        original_rgb = cv2.cvtColor(original_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        unique = np.unique(ids_map)\n",
    "        n_classes = int(unique.size)\n",
    "        road_pct     = float((ids_map == 0).mean())\n",
    "        sidewalk_pct = float((ids_map == 1).mean())\n",
    "\n",
    "        road_conf = sidewalk_conf = np.nan\n",
    "        if conf_map is not None:\n",
    "            m0 = (ids_map == 0); m1 = (ids_map == 1)\n",
    "            if m0.any(): road_conf     = float(conf_map[m0].mean())\n",
    "            if m1.any(): sidewalk_conf = float(conf_map[m1].mean())\n",
    "\n",
    "        mask_rgb, present_classes = filter_mask_ids(ids_map)\n",
    "        mask_resized = cv2.resize(mask_rgb, (original_rgb.shape[1], original_rgb.shape[0]),\n",
    "                                  interpolation=cv2.INTER_NEAREST)\n",
    "        overlay = cv2.addWeighted(original_rgb, 1 - alpha, mask_resized, alpha, 0)\n",
    "\n",
    "        if save_ids_conf:\n",
    "            ids_out  = os.path.join(output_dir, f\"{stem}_ids.png\")\n",
    "            cv2.imwrite(ids_out, ids_map)  # uint8 0..18\n",
    "            if conf_map is not None:\n",
    "                conf_8 = (np.clip(conf_map, 0, 1) * 255).astype(np.uint8)\n",
    "                cv2.imwrite(os.path.join(output_dir, f\"{stem}_conf.png\"), conf_8)\n",
    "\n",
    "        legend_patches = []\n",
    "        for class_id in present_classes:\n",
    "            color_rgb = tuple(np.array(CITYSCAPES_ID2COLOR[class_id]) / 255.0)\n",
    "            label = \"road\" if class_id == 0 else \"sidewalk\"\n",
    "            legend_patches.append(plt.Rectangle((0,0),1,1, fc=color_rgb, label=label))\n",
    "\n",
    "        road_conf_txt     = \"—\" if np.isnan(road_conf) else f\"{road_conf:.3f}\"\n",
    "        sidewalk_conf_txt = \"—\" if np.isnan(sidewalk_conf) else f\"{sidewalk_conf:.3f}\"\n",
    "        title = (\n",
    "            f\"{'LINEAR'}: {len(present_classes)} de las 2 clases de interés\"\n",
    "            f\"\\nnúmero total de clases: {n_classes}\"\n",
    "            f\"\\nroad: {road_pct*100:.3f}% (conf {road_conf_txt}) \"\n",
    "            f\"| sidewalk: {sidewalk_pct*100:.3f}% (conf {sidewalk_conf_txt})\"\n",
    "        )\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        axes[0].imshow(original_rgb); axes[0].set_title(f'Original\\n{stem}'); axes[0].axis('off')\n",
    "        axes[1].imshow(overlay); axes[1].set_title(title); axes[1].axis('off')\n",
    "        if legend_patches:\n",
    "            fig.legend(handles=legend_patches, loc='lower center', ncol=len(legend_patches))\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "        if save_vis:\n",
    "            out_path = os.path.join(output_dir, f\"{stem}_ocrnet_vis.jpg\")\n",
    "            cv2.imwrite(out_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        results_lst.append({\n",
    "            'method_name': 'LINEAR',\n",
    "            'image_name': fname,\n",
    "            'n_classes': n_classes,\n",
    "            'road_pct': round(road_pct*100, 3),\n",
    "            'sidewalk_pct': round(sidewalk_pct*100, 3),\n",
    "            'road_conf': None if np.isnan(road_conf) else road_conf,\n",
    "            'sidewalk_conf': None if np.isnan(sidewalk_conf) else sidewalk_conf\n",
    "        })\n",
    "\n",
    "        print(f\"{stem}: clases={n_classes} | road%={road_pct*100:.3f} | sidewalk%={sidewalk_pct*100:.3f} \"\n",
    "              f\"| conf road={road_conf_txt} | conf sidewalk={sidewalk_conf_txt}\")\n",
    "\n",
    "    return results_lst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8cadbc",
   "metadata": {},
   "source": [
    "# Experimentos con imágenes del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94504734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_dir = \"/home/joan_ds/Sandbox/UOC/TFM/trials_imgs\"\n",
    "results_dataset = mask_pred_hrnet(model=model, input_dir=input_dir, output_dir=\"ocrnet_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ebdd1",
   "metadata": {},
   "source": [
    "# Experimentos con imágenes de los benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdd100k = {'name': 'BDD100K', 'path': '/home/joan_ds/Sandbox/UOC/TFM/benchmarks/BDD100K'}\n",
    "cityscapes = {'name': 'Cityscapes', 'path': '/home/joan_ds/Sandbox/UOC/TFM/benchmarks/Cityscapes'}\n",
    "mapillary_vistas = {'name': 'Mapillary Vistas', 'path': '/home/joan_ds/Sandbox/UOC/TFM/benchmarks/Mapillary_Vistas'}\n",
    "\n",
    "benchmark_lst = [bdd100k, cityscapes, mapillary_vistas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_benchmarks_lst = []\n",
    "\n",
    "for benchmark in benchmark_lst:\n",
    "    print (f\"Segmentación con el submuestreo del dataset {benchmark['name']}.\")\n",
    "\n",
    "    results_benchmark = mask_pred_hrnet(model=model, input_dir=benchmark['path'], output_dir=\"hrnet_output\")\n",
    "    results_benchmarks_lst.append(results_benchmark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bfcbc3",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db3c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_benchmarks_flatten = [dicc for lst in results_benchmarks_lst for dicc in lst]\n",
    "\n",
    "results_dataset_flatten = [dicc for dicc in results_dataset]\n",
    "\n",
    "results_dataset_df = pd.DataFrame(results_dataset_flatten)\n",
    "results_benchmarks_df = pd.DataFrame(results_benchmarks_flatten)\n",
    "\n",
    "df = pd.concat([results_dataset_df, results_benchmarks_df]).reset_index(drop=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5086a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_name == df.image_name[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c435b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('20250814_results_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da45a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_HRNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
