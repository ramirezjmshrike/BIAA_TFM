{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc33f4be",
   "metadata": {},
   "source": [
    "# Carga de librerías y métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba89f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.serialization import safe_globals\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18558fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/home/joan_ds/Sandbox/UOC/TFM/tfm_deeplab/DeepLabV3Plus-Pytorch/best_deeplabv3plus_mobilenet_cityscapes_os16.pth\"\n",
    "print(\"¿Existe?\", os.path.isfile(ckpt_path), ckpt_path)\n",
    "\n",
    "\n",
    "try:\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "except Exception:\n",
    "    with safe_globals([np.core.multiarray.scalar]):\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=True)\n",
    "\n",
    "print(type(ckpt), ckpt.keys() if isinstance(ckpt, dict) else \"no dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/home/joan_ds/Sandbox/UOC/TFM/trials_imgs'\n",
    "tmp_dir = 'DeepLabV3Plus-Pytorch/tmp_resized'\n",
    "output_dir = 'DeepLabV3Plus-Pytorch/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITYSCAPES_ID2COLOR = {\n",
    "    0: (128, 64, 128),  # road\n",
    "    1: (244, 35, 232)   # sidewalk\n",
    "}\n",
    "\n",
    "def filter_mask_ids(ids_map):\n",
    "    h, w = ids_map.shape\n",
    "    mask_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    present_classes = []\n",
    "    for class_id, color in CITYSCAPES_ID2COLOR.items():\n",
    "        m = (ids_map == class_id)\n",
    "        if m.any():\n",
    "            mask_rgb[m] = color\n",
    "            present_classes.append(class_id)\n",
    "    return mask_rgb, present_classes\n",
    "\n",
    "def mask_pred(resample_method: dict, input_dir=input_dir, tmp_dir=tmp_dir, output_dir=output_dir):\n",
    "    method_name  = resample_method['name']\n",
    "    method_Image = resample_method['method_Image']\n",
    "    method_cv2   = resample_method['method_cv2']\n",
    "\n",
    "    results_lst = []\n",
    "    \n",
    "\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "    for fname in os.listdir(input_dir):\n",
    "        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(input_dir, fname)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img.resize((2048, 1024), method_Image).save(\n",
    "                os.path.join(tmp_dir, os.path.splitext(fname)[0] + '.png')\n",
    "            )\n",
    "            \n",
    "\n",
    "    !cd DeepLabV3Plus-Pytorch && \\\n",
    "    python /home/joan_ds/Sandbox/UOC/TFM/tfm_deeplab/DeepLabV3Plus-Pytorch/predict.py \\\n",
    "        --model deeplabv3plus_mobilenet \\\n",
    "        --dataset cityscapes \\\n",
    "        --ckpt /home/joan_ds/Sandbox/UOC/TFM/tfm_deeplab/DeepLabV3Plus-Pytorch/best_deeplabv3plus_mobilenet_cityscapes_os16.pth \\\n",
    "        --input \"tmp_resized\" \\\n",
    "        --save_val_results_to output\n",
    "\n",
    "    for fname in os.listdir(output_dir):\n",
    "        if not fname.endswith('_ids.png'):\n",
    "            continue\n",
    "\n",
    "        name = fname.replace('_ids.png', '')\n",
    "        dicc = {'method_name': method_name, 'image_name': fname}\n",
    "        ids_path  = os.path.join(output_dir, fname)\n",
    "        conf_path = os.path.join(output_dir, name + '_conf.png')\n",
    "\n",
    "        # trobar original\n",
    "        orig_path = next(\n",
    "            (os.path.join(input_dir, name + ext) for ext in ('.jpg', '.jpeg', '.png')\n",
    "             if os.path.exists(os.path.join(input_dir, name + ext))),\n",
    "            None\n",
    "        )\n",
    "        if orig_path is None: \n",
    "            continue\n",
    "\n",
    "        original = cv2.cvtColor(cv2.imread(orig_path), cv2.COLOR_BGR2RGB)\n",
    "        ids_map  = cv2.imread(ids_path,  cv2.IMREAD_GRAYSCALE)\n",
    "        conf_map = cv2.imread(conf_path, cv2.IMREAD_GRAYSCALE) if os.path.exists(conf_path) else None\n",
    "\n",
    "        \n",
    "        road_pct     = float((ids_map == 0).mean())\n",
    "        sidewalk_pct = float((ids_map == 1).mean())\n",
    "        n_classes = len(np.unique(ids_map))\n",
    "        dicc |= {'n_classes': n_classes, 'road_pct': round(road_pct * 100, 3), 'sidewalk_pct': round(sidewalk_pct * 100, 3)}\n",
    "        results_lst.append(dicc)\n",
    "\n",
    "        # confiances (si tenim conf_map)\n",
    "        road_conf = sidewalk_conf = np.nan\n",
    "        if conf_map is not None:\n",
    "            conf_float = conf_map.astype(np.float32) / 255.0\n",
    "            m0 = (ids_map == 0); m1 = (ids_map == 1)\n",
    "            if m0.any(): road_conf     = float(conf_float[m0].mean())\n",
    "            if m1.any(): sidewalk_conf = float(conf_float[m1].mean())\n",
    "            dicc |= {'road_conf': road_conf, 'sidewalk_conf': sidewalk_conf}\n",
    "\n",
    "        print(f\"\\nEn {name} se detectan {n_classes} clases diferentes.\")\n",
    "        print(f\"Proporciones sobre píxels:\\nroad: {road_pct * 100:.3f} %\\nsidewalk: {sidewalk_pct * 100:.3f} %\",\n",
    "              f\"\\nConfianza media en la predicción (logits):\\nmeanConf(road) = {road_conf:.3f}\\nmeanConf(sidewalk) = {sidewalk_conf:.3f}\")\n",
    "\n",
    "        # màscara RGB i overlay\n",
    "        mask_rgb, present_classes = filter_mask_ids(ids_map)\n",
    "        mask_resized = cv2.resize(mask_rgb, (original.shape[1], original.shape[0]),\n",
    "                                  interpolation=method_cv2)\n",
    "        overlay = cv2.addWeighted(original, 0.5, mask_resized, 0.5, 0)\n",
    "\n",
    "        # llegenda\n",
    "        legend_patches = []\n",
    "        for class_id in present_classes:\n",
    "            color_rgb = tuple(np.array(CITYSCAPES_ID2COLOR[class_id]) / 255.0)\n",
    "            label = \"road\" if class_id == 0 else \"sidewalk\"\n",
    "            legend_patches.append(plt.Rectangle((0,0),1,1, fc=color_rgb, label=label))\n",
    "\n",
    "        # títol amb resum “proxy”\n",
    "        present_n = len(present_classes)\n",
    "        if np.isnan(road_conf):     road_conf_txt = \"—\"\n",
    "        else:                       road_conf_txt = f\"{road_conf:.3f}\"\n",
    "        if np.isnan(sidewalk_conf): sidewalk_conf_txt = \"—\"\n",
    "        else:                       sidewalk_conf_txt = f\"{sidewalk_conf:.3f}\"\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        axes[0].imshow(original); axes[0].set_title(f'Original\\nImagen {name}'); axes[0].axis('off')\n",
    "        axes[1].imshow(overlay)\n",
    "        axes[1].set_title(\n",
    "            f\"{method_name} – {present_n} clases presentes de las 2 clases de interés\\n\"\n",
    "            f\"road: {road_pct * 100:.3f} %, conf {road_conf_txt} | \"\n",
    "            f\"sidewalk: {sidewalk_pct * 100:.3f} %, conf {sidewalk_conf_txt}\"\n",
    "        )\n",
    "        axes[1].axis('off')\n",
    "        if legend_patches:\n",
    "            fig.legend(handles=legend_patches, loc='lower center', ncol=len(legend_patches))\n",
    "        plt.tight_layout(); plt.show()\n",
    "    \n",
    "    return results_lst\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b372bc3",
   "metadata": {},
   "source": [
    "# Experimentos con imágenes del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31768cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = {'name': 'LINEAR', 'method_Image': Image.BILINEAR, 'method_cv2': cv2.INTER_LINEAR}\n",
    "nearest = {'name': 'NEAREST', 'method_Image': Image.NEAREST, 'method_cv2': cv2.INTER_NEAREST}\n",
    "cubic = {'name': 'CUBIC', 'method_Image': Image.BICUBIC, 'method_cv2': cv2.INTER_CUBIC}\n",
    "\n",
    "methods_lst = [linear, nearest, cubic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataset = []\n",
    "\n",
    "for method in methods_lst:\n",
    "    sup_title = f\"Resultados tras redimensionar las imaǵenes con el método de remuestreo {method['name']}\"\n",
    "\n",
    "    print(sup_title)\n",
    "\n",
    "    results_dataset.append(mask_pred(method))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ebdd1",
   "metadata": {},
   "source": [
    "# Experimentos con imágenes de los benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdd100k = {'name': 'BDD100K', 'path': '/home/joan_ds/Sandbox/UOC/TFM/benchmarks/BDD100K'}\n",
    "cityscapes = {'name': 'Cityscapes', 'path': '/home/joan_ds/Sandbox/UOC/TFM/benchmarks/Cityscapes'}\n",
    "mapillary_vistas = {'name': 'Mapillary Vistas', 'path': '/home/joan_ds/Sandbox/UOC/TFM/benchmarks/Mapillary_Vistas'}\n",
    "\n",
    "benchmark_lst = [bdd100k, cityscapes, mapillary_vistas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_benchmarks_lst = []\n",
    "\n",
    "for benchmark in benchmark_lst:\n",
    "    print (f\"Segmentación con el submuestreo del dataset {benchmark['name']}.\")\n",
    "\n",
    "    for method in methods_lst:\n",
    "        sup_title = f\"Resultados tras redimensionar las imaǵenes con el método de remuestreo {method['name']}\"\n",
    "\n",
    "        print(sup_title)\n",
    "\n",
    "        results_benchmark = mask_pred(method, input_dir=benchmark['path'])\n",
    "        results_benchmarks_lst.append(results_benchmark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bfcbc3",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db3c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_benchmarks_flatten = [dicc for lst in results_benchmarks_lst for dicc in lst]\n",
    "\n",
    "results_dataset_flatten = [dicc for lst in results_dataset for dicc in lst]\n",
    "\n",
    "results_dataset_df = pd.DataFrame(results_dataset_flatten)\n",
    "results_benchmarks_df = pd.DataFrame(results_benchmarks_flatten)\n",
    "\n",
    "df = pd.concat([results_dataset_df, results_benchmarks_df]).reset_index(drop=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5086a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.image_name == df.image_name[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c435b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('20250813_results_analysis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da45a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_deeplab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
